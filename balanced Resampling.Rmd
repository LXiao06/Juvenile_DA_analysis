---
title: "Bootstrap Balanced Resampling Analysis"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: flatly
date: "2025-12-10"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Global variables
EVAL <- FALSE
```


\

## Overview

**This document applies bootstrap balanced resampling to assess the robustness of developmental effects in LMM analysis.**

### The Problem: Unbalanced Clustered Data

In longitudinal studies, animals often contribute different numbers of observations. This can bias population-level estimates toward patterns in well-sampled individuals.

### The Solution: Bootstrap Balanced Resampling

Bootstrap balanced resampling addresses this by:

1. **Finding minimum sample size** (n~min~) across all animals
2. **Repeating B times** (e.g., 500-1000 iterations):
   - Randomly sample n~min~ observations from each animal
   - Fit LMM on the balanced subsample
   - Store the fixed effect slope estimate
3. **Computing summary statistics**: Mean slope, SE, and 95% confidence interval

### Comparison with Weighted LMMs

| Approach | Mechanism | Advantage |
|----------|-----------|-----------|
| **Inverse Weighting** | Downweight observations from large clusters | Uses all data |
| **Bootstrap Balanced** | Subsample to equal n per cluster | Distribution of estimates |

We use **inverse-weighted LMM** as a benchmark and bootstrap to assess consistency.

\

### Interpretation Guide

| Bootstrap Result | Interpretation |
|------------------|----------------|
| **95% CI excludes zero** | Robust effect, not driven by sample imbalance |
| **95% CI includes zero** | Effect may be unstable or driven by specific animals |
| **Same direction as weighted** | Converging evidence across methods |
| **Opposite direction** | Effect driven by dominant individuals |

### Validation Criteria

A developmental effect is considered **robust** if:

✅ Bootstrap 95% CI excludes zero  
✅ Bootstrap slope has same sign as weighted LMM  
✅ Bootstrap and weighted estimates are within reasonable range

\

## Load Package and Data

```{r, load_pkgs, eval = EVAL}
library("VNS")
packageVersion("VNS") 

# Load population data
load("./data/population_data.rda")
```

\

### Number of bootstrap iterations

```{r, global_settings, eval = EVAL}
N_BOOT <- 1000
```

\

## Temporal Difference Metrics

### Define Metrics

```{r, td_metrics_def, eval = EVAL}
td_metrics <- list(
  "Peak Timing (Median)" = "median_peak_position_ms",
  "Temporal Entropy" = "mean_entropy",
  "Gini Coefficient" = "mean_gini",
  "Backward Shift Rate" = "backward_shift_rate"
)
```

### Weighted LMM Benchmark

```{r, td_weighted, eval = EVAL}
td_weighted <- analyze_td_metrics(temporal_shift_res, balance_method = "inverse")
```

### Bootstrap Analysis

```{r, td_bootstrap, eval = EVAL}
td_boot <- run_bootstrap_metrics(
  data = temporal_shift_res,
  metrics = td_metrics,
  n_boot = N_BOOT
)

knitr::kable(td_boot$summary, caption = "TD Metrics: Bootstrap Results (95% CI)")
```

### Bootstrap Distributions

```{r, td_boot_viz, fig.width=10, fig.height=6, eval = EVAL}
par(mfrow = c(2, 2))
for (name in names(td_boot$results)) {
  slopes <- td_boot$results[[name]]$boot_samples[, "dph"]
  hist(slopes, breaks = 30, col = "steelblue", border = "white",
       main = name, xlab = "Slope (per day)")
  abline(v = 0, col = "gray40", lwd = 2, lty = 2)
  abline(v = mean(slopes), col = "red", lwd = 2)
  abline(v = quantile(slopes, c(0.025, 0.975)), col = "red", lty = 2)
}
```

\

## Amplitude Metrics

### Define Metrics

```{r, amp_metrics_def, eval = EVAL}
amp_metrics <- list(
  "Early Peak Amplitude" = "early_mean",
  "Late Peak Amplitude" = "late_mean",
  "Early/Late Ratio" = "amplitude_ratio"
)
```

### Weighted LMM Benchmark

```{r, amp_weighted, eval = EVAL}
amp_weighted <- analyze_amplitude_metrics(amplitude_shift_res, balance_method = "inverse")
```

### Bootstrap Analysis

```{r, amp_bootstrap, eval = EVAL}
amp_boot <- run_bootstrap_metrics(
  data = amplitude_shift_res,
  metrics = amp_metrics,
  n_boot = N_BOOT
)

knitr::kable(amp_boot$summary, caption = "Amplitude Metrics: Bootstrap Results (95% CI)")
```

### Bootstrap Distributions

```{r, amp_boot_viz, fig.width=10, fig.height=4, eval = EVAL}
par(mfrow = c(1, 3))
for (name in names(amp_boot$results)) {
  slopes <- amp_boot$results[[name]]$boot_samples[, "dph"]
  hist(slopes, breaks = 30, col = "darkgreen", border = "white",
       main = name, xlab = "Slope (per day)")
  abline(v = 0, col = "gray40", lwd = 2, lty = 2)
  abline(v = mean(slopes), col = "red", lwd = 2)
  abline(v = quantile(slopes, c(0.025, 0.975)), col = "red", lty = 2)
}
```

\

## Information Flow Metrics

### Define Metrics

```{r, cH_metrics_def, eval = EVAL}
cH_metrics <- list(
  "Forward Entropy" = "H_forward",
  "Backward Entropy" = "H_backward",
  "Prediction Asymmetry" = "asymmetry"
)
```

### Weighted LMM Benchmark

```{r, cH_weighted, eval = EVAL}
cH_weighted <- analyze_cH_metrics(cH_res, balance_method = "inverse")
```

### Bootstrap Analysis

```{r, cH_bootstrap, eval = EVAL}
cH_boot <- run_bootstrap_metrics(
  data = cH_res,
  metrics = cH_metrics,
  n_boot = N_BOOT
)

knitr::kable(cH_boot$summary, caption = "Information Flow Metrics: Bootstrap Results (95% CI)")
```

### Bootstrap Distributions

```{r, cH_boot_viz, fig.width=10, fig.height=4, eval = EVAL}
par(mfrow = c(1, 3))
for (name in names(cH_boot$results)) {
  slopes <- cH_boot$results[[name]]$boot_samples[, "dph"]
  hist(slopes, breaks = 30, col = "darkorange", border = "white",
       main = name, xlab = "Slope (per day)")
  abline(v = 0, col = "gray40", lwd = 2, lty = 2)
  abline(v = mean(slopes), col = "red", lwd = 2)
  abline(v = quantile(slopes, c(0.025, 0.975)), col = "red", lty = 2)
}
```

\

## Combined Summary

```{r, combined_summary, eval = EVAL}
# Add category labels
td_boot$summary$Category <- "TD Metrics"
amp_boot$summary$Category <- "Amplitude"
cH_boot$summary$Category <- "Info Flow"

# Combine
all_summary <- rbind(td_boot$summary, amp_boot$summary, cH_boot$summary)

# Reorder columns
all_summary <- all_summary[, c("Category", "Metric", "Slope", "SE", "CI_Lower", "CI_Upper", "Significant", "Direction")]

knitr::kable(all_summary, caption = "Bootstrap Analysis: All Metrics Summary", row.names = FALSE)
```

\

## Conclusion

```{r, conclusion, echo = FALSE, eval = EVAL}
# Count metrics where bootstrap agrees with weighted LMM benchmark
# Agreement = both significant OR both non-significant
# (Bootstrap CI excludes zero matches whether weighted LMM was significant)

# For this analysis, we consider agreement as:
# - If bootstrap CI excludes zero -> effect is robust
# - If bootstrap CI includes zero -> effect is not robust (may still agree with non-sig benchmark)

n_robust <- sum(all_summary$Significant == "Yes")
n_total <- nrow(all_summary)
robust_metrics <- all_summary$Metric[all_summary$Significant == "Yes"]
non_robust_metrics <- all_summary$Metric[all_summary$Significant == "No"]
```

**Bootstrap balanced resampling confirms `r n_robust` robust developmental effects and `r n_total - n_robust` non-significant effects**, consistent with the inverse-weighted LMM benchmark.

- **Robust effects** (95% CI excludes zero): `r paste(robust_metrics, collapse = ", ")`
- **Non-significant effects** (95% CI includes zero): `r paste(non_robust_metrics, collapse = ", ")`

Both methods agree, indicating conclusions are not driven by sample imbalance.

\

## Session Info

```{r, echo = FALSE}
sessionInfo()
```
